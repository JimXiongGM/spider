{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.common_utils import read_json\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# table.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n",
      "206\n"
     ]
    }
   ],
   "source": [
    "train_table = read_json(\"data/tables.json\")\n",
    "print(len(train_table))\n",
    "\n",
    "test_table = read_json(\"data/test_data/tables.json\")\n",
    "print(len(test_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n",
      "206\n"
     ]
    }
   ],
   "source": [
    "# 看看路径数量是否匹配\n",
    "train_paths = glob(\"data/database/*\")\n",
    "train_paths = [p for p in train_paths if os.path.isdir(p)]\n",
    "print(len(train_paths))\n",
    "\n",
    "# test\n",
    "test_paths = glob(\"data/test_database/*\")\n",
    "test_paths = [p for p in test_paths if os.path.isdir(p)]\n",
    "print(len(test_paths))\n",
    "\n",
    "# 为什么要复制一遍？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dbs = [os.path.basename(p) for p in train_paths]\n",
    "test_dbs = [os.path.basename(p) for p in test_paths]\n",
    "\n",
    "# in test not in train\n",
    "not_in_train = [db for db in test_dbs if db not in train_dbs]\n",
    "len(not_in_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aan_1', 'address_1', 'advertising_agencies', 'art_1', 'bakery_1', 'bbc_channels', 'bike_racing', 'boat_1', 'book_1', 'book_press', 'book_review', 'car_racing', 'car_road_race', 'club_leader', 'conference', 'country_language', 'cre_Doc_Workflow', 'cre_Doc_and_collections', 'cre_Students_Information_Systems', 'customers_and_orders', 'district_spokesman', 'e_commerce', 'government_shift', 'headphone_store', 'institution_sports', 'movie_2', 'online_exams', 'pilot_1', 'planet_1', 'real_estate_rentals', 'region_building', 'restaurant_bills', 'sing_contest', 'soccer_3', 'tv_shows', 'university_rank', 'vehicle_driver', 'vehicle_rent', 'video_game', 'warehouse_1']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(not_in_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8659"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = read_json(\"data/train_spider.json\") + read_json(\"data/train_others.json\")\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['db_id', 'query', 'query_toks', 'query_toks_no_value', 'question', 'question_toks', 'sql'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "d= train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many heads of the departments are older than 56 ?\n",
      "SELECT count(*) FROM head WHERE age  >  56\n",
      "{'from': {'table_units': [['table_unit', 1]], 'conds': []}, 'select': [False, [[3, [0, [0, 0, False], None]]]], 'where': [[False, 3, [0, [0, 10, False], None], 56.0, None]], 'groupBy': [], 'having': [], 'orderBy': [], 'limit': None, 'intersect': None, 'union': None, 'except': None}\n"
     ]
    }
   ],
   "source": [
    "print(d[\"question\"])\n",
    "print(d[\"query\"])\n",
    "print(d[\"sql\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_table = read_json(\"data/tables.json\")\n",
    "len(train_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['column_names', 'column_names_original', 'column_types', 'db_id', 'foreign_keys', 'primary_keys', 'table_names', 'table_names_original'])\n"
     ]
    }
   ],
   "source": [
    "print(train_table[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"LLMs/meta-llama/Meta-Llama-3-8B/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count db_id\n",
    "db_id_count = defaultdict(int)\n",
    "for d in train_data:\n",
    "    db_id_count[d[\"db_id\"]] += 1\n",
    "# sort by name\n",
    "db_id_count = sorted(db_id_count.items(), key=lambda x: x[0])\n",
    "# db_id_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照DB ID 统计问题和SQL的长度\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "types = [d[0] for d in db_id_count]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=(len(types) + 4) // 5, ncols=5, figsize=(15, 5 * ((len(types) + 4) // 5)))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, tp in enumerate(tqdm(types)):\n",
    "    tp_data = [d for d in train_data if d[\"db_id\"] == tp] # db_id or difficulty\n",
    "\n",
    "    lengths_question = []\n",
    "    lengths_SQL = []\n",
    "\n",
    "    for d in tp_data:\n",
    "        lengths_question.append(len(tokenizer.tokenize(d['question'])))\n",
    "        lengths_SQL.append(len(tokenizer.tokenize(d['query'])))\n",
    "\n",
    "    ax = axes[idx]\n",
    "    ax.hist(lengths_question, bins=20, color='skyblue', edgecolor='black', alpha=0.5, label='question')\n",
    "    ax.hist(lengths_SQL, bins=20, color='orange', edgecolor='black', alpha=0.5, label='SQL') \n",
    "    ax.set_title(f'{tp}')\n",
    "    ax.set_xlabel('Length of tokens')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "for ax in axes[idx+1:]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "os.makedirs(\"img\", exist_ok=True)\n",
    "plt.savefig(\"img/train-db-q-sql-token-length.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 xionggm xionggm 1.5M  6月 18 22:23 img/train-db-q-sql-token-length.png\n"
     ]
    }
   ],
   "source": [
    "!ls -lh img/train-db-q-sql-token-length.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB schema 打印"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from glob import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_tables(cursor):\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    # exclude sqlite_sequence\n",
    "    tables = [table[0] for table in tables if table[0] != \"sqlite_sequence\"]\n",
    "    return tables\n",
    "\n",
    "def get_primary_key(cursor, table_name):\n",
    "    cursor.execute(f\"PRAGMA table_info(`{table_name}`)\")\n",
    "    columns = cursor.fetchall()\n",
    "    primary_keys = [col[1] for col in columns if col[5] == 1]\n",
    "    return primary_keys\n",
    "\n",
    "def get_foreign_keys(cursor, table_name):\n",
    "    cursor.execute(f\"PRAGMA foreign_key_list(`{table_name}`)\")\n",
    "    foreign_keys = cursor.fetchall()\n",
    "    return foreign_keys\n",
    "\n",
    "def generate_markdown_table(cursor):\n",
    "    tables = get_tables(cursor)\n",
    "    markdown = \"| Table | Primary Key | Foreign Key |\\n\"\n",
    "    markdown += \"| --- | --- | --- |\\n\"\n",
    "    \n",
    "    for table in sorted(tables):\n",
    "        primary_keys = get_primary_key(cursor, table)\n",
    "        foreign_keys = get_foreign_keys(cursor, table)\n",
    "\n",
    "        primary_key_str = \", \".join(primary_keys)\n",
    "\n",
    "        foreign_key_str = \"\"\n",
    "        if foreign_keys:\n",
    "            # fk[2]: table name, fk[3]: column name, fk[4]: parent column name\n",
    "            foreign_key_str = \", \".join([f\"{fk[3]} references {fk[2]}({fk[4]})\" for fk in foreign_keys])\n",
    "\n",
    "        markdown += f\"| {table} | {primary_key_str} | {foreign_key_str} |\\n\"\n",
    "\n",
    "    return markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Table | Primary Key | Foreign Key |\n",
      "| --- | --- | --- |\n",
      "| author | aid |  |\n",
      "| cite |  | citing references publication(pid), cited references publication(pid) |\n",
      "| conference | cid |  |\n",
      "| domain | did |  |\n",
      "| domain_author | did | did references domain(did), aid references author(aid) |\n",
      "| domain_conference | did | did references domain(did), cid references conference(cid) |\n",
      "| domain_journal | did | did references domain(did), jid references journal(jid) |\n",
      "| domain_keyword | did | did references domain(did), kid references keyword(kid) |\n",
      "| domain_publication | did | did references domain(did), pid references publication(pid) |\n",
      "| journal | jid |  |\n",
      "| keyword | kid |  |\n",
      "| organization | oid |  |\n",
      "| publication | pid | cid references conference(cid), jid references journal(jid) |\n",
      "| publication_keyword | kid | kid references keyword(kid), pid references publication(pid) |\n",
      "| writes | aid | aid references author(aid), pid references publication(pid) |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "db_path = 'data/database/academic/academic.sqlite'\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "markdown_table = generate_markdown_table(cursor)\n",
    "print(markdown_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
